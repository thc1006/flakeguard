/**
 * Standalone Check Runs Integration Test
 * 
 * Demonstrates the Check Runs rendering system functionality without dependencies.
 * This file contains inline implementations of the core functions to showcase
 * the rendering logic and validation constraints.
 */

// Core types (inline for demonstration)
/**
 * @typedef {Object} TestCandidate
 * @property {string} testName
 * @property {number} failCount
 * @property {number} rerunPassRate
 * @property {string|null} lastFailedRun
 * @property {number} confidence
 * @property {string|null} failurePattern
 * @property {number} totalRuns
 */

/**
 * @typedef {Object} CheckRunOutput
 * @property {string} title
 * @property {string} summary
 */

/**
 * @typedef {Object} CheckRunActionDef
 * @property {string} label
 * @property {string} description
 * @property {string} identifier
 */

// Action configurations
const CHECK_RUN_ACTION_CONFIGS = {
  rerun_failed: {
    label: 'Rerun Failed Jobs',
    description: 'Rerun only the failed jobs in this workflow'
  },
  quarantine: {
    label: 'Quarantine Tests',
    description: 'Mark tests as quarantined to prevent CI disruption'
  },
  open_issue: {
    label: 'Open Issue',
    description: 'Create GitHub issue to track flaky test'
  }
};

/**
 * Generate markdown summary for flaky test candidates
 * @param {TestCandidate[]} tests - Array of test candidates
 * @returns {CheckRunOutput}
 */
function renderCheckRunOutput(tests) {
  if (tests.length === 0) {
    return {
      title: '✅ FlakeGuard Analysis Complete',
      summary: 'No flaky test candidates detected in this run.\n\nAll tests appear to be stable based on historical analysis.'
    };
  }

  const title = `🔍 FlakeGuard Analysis: ${tests.length} Flaky Test Candidate${tests.length === 1 ? '' : 's'} Detected`;
  
  let summary = '## Flaky Test Candidates\n\n';
  summary += 'The following tests show patterns consistent with flaky behavior:\n\n';
  
  // Create markdown table
  summary += '| Test Name | Fail Count | Rerun Pass Rate | Last Failed Run | Confidence |\n';
  summary += '|-----------|------------|-----------------|-----------------|------------|\n';
  
  // Sort tests by confidence (desc) then fail count (desc)
  const sortedTests = [...tests]
    .sort((a, b) => {
      if (b.confidence !== a.confidence) {
        return b.confidence - a.confidence;
      }
      return b.failCount - a.failCount;
    })
    .slice(0, 10); // Limit to top 10
    
  for (const test of sortedTests) {
    const passRate = `${(test.rerunPassRate * 100).toFixed(1)}%`;
    const confidence = `${(test.confidence * 100).toFixed(1)}%`;
    const lastRun = test.lastFailedRun 
      ? new Date(test.lastFailedRun).toLocaleDateString()
      : 'N/A';
    
    summary += `| \`${escapeMarkdown(test.testName)}\` | ${test.failCount} | ${passRate} | ${lastRun} | ${confidence} |\n`;
  }
  
  summary += '\n';
  
  if (tests.length > 10) {
    summary += `*Showing top 10 of ${tests.length} total candidates.*\n\n`;
  }
  
  // Add explanation
  summary += '### What are flaky tests?\n\n';
  summary += 'Flaky tests are tests that exhibit both passing and failing results without changes to the code. ';
  summary += 'They can be caused by:\n\n';
  summary += '- **Race conditions** - Timing-dependent code execution\n';
  summary += '- **External dependencies** - Network calls, databases, file system\n';
  summary += '- **Resource contention** - Insufficient memory, CPU, or I/O\n';
  summary += '- **Non-deterministic behavior** - Random values, system time dependencies\n\n';
  
  // Add recommendations
  summary += '### Recommended Actions\n\n';
  summary += '1. **Quarantine** high-confidence flaky tests to prevent CI instability\n';
  summary += '2. **Rerun** failed jobs to confirm flaky behavior\n';
  summary += '3. **Open issues** to track and fix root causes\n\n';
  
  summary += '*This analysis is generated by FlakeGuard based on historical test execution data.*';
  
  return { title, summary };
}

/**
 * Generate exactly ≤3 requested actions
 * @param {TestCandidate[]} tests - Array of test candidates
 * @param {boolean} hasFailures - Whether there are test failures
 * @returns {CheckRunActionDef[]}
 */
function generateCheckRunActions(tests, hasFailures) {
  const actions = [];
  
  // Always allow rerunning failed jobs if there are failures
  if (hasFailures && actions.length < 3) {
    actions.push({
      label: CHECK_RUN_ACTION_CONFIGS.rerun_failed.label,
      description: CHECK_RUN_ACTION_CONFIGS.rerun_failed.description,
      identifier: 'rerun_failed'
    });
  }
  
  // High-confidence flaky tests get quarantine suggestion
  const highConfidenceTests = tests.filter(t => t.confidence >= 0.7);
  if (highConfidenceTests.length > 0 && actions.length < 3) {
    actions.push({
      label: CHECK_RUN_ACTION_CONFIGS.quarantine.label,
      description: `Quarantine ${highConfidenceTests.length} high-confidence flaky test${highConfidenceTests.length === 1 ? '' : 's'}`,
      identifier: 'quarantine'
    });
  }
  
  // Any flaky tests get issue creation suggestion
  if (tests.length > 0 && actions.length < 3) {
    actions.push({
      label: CHECK_RUN_ACTION_CONFIGS.open_issue.label,
      description: `Create issue for ${tests.length} flaky test candidate${tests.length === 1 ? '' : 's'}`,
      identifier: 'open_issue'
    });
  }
  
  // Ensure we never exceed 3 actions
  return actions.slice(0, 3);
}

/**
 * Escape markdown special characters
 * @param {string} text - Text to escape
 * @returns {string}
 */
function escapeMarkdown(text) {
  return text.replace(/([\\`*_{}\[\]()#+\-.!])/g, '\\$1');
}

/**
 * Create a test candidate
 * @param {Partial<TestCandidate>} overrides - Property overrides
 * @returns {TestCandidate}
 */
function createTestCandidate(overrides = {}) {
  return {
    testName: 'com.example.TestClass.testMethod',
    failCount: 5,
    rerunPassRate: 0.75,
    lastFailedRun: '2024-01-15T10:30:00.000Z',
    confidence: 0.8,
    failurePattern: 'timeout',
    totalRuns: 20,
    ...overrides
  };
}

// Test Suite
function runTests() {
  console.log('🧪 FlakeGuard Check Runs Standalone Test Suite\n');
  
  let passed = 0;
  let failed = 0;
  
  function assert(condition, message) {
    if (condition) {
      console.log(`✅ ${message}`);
      passed++;
    } else {
      console.error(`❌ ${message}`);
      failed++;
    }
  }
  
  // Test 1: Empty state rendering
  console.log('Test 1: Empty state rendering');
  const emptyOutput = renderCheckRunOutput([]);
  assert(emptyOutput.title.includes('FlakeGuard Analysis Complete'), 'Empty state has correct title');
  assert(emptyOutput.summary.includes('No flaky test candidates'), 'Empty state has correct summary');
  console.log();
  
  // Test 2: Single candidate rendering
  console.log('Test 2: Single candidate rendering');
  const singleCandidate = createTestCandidate();
  const singleOutput = renderCheckRunOutput([singleCandidate]);
  assert(singleOutput.title.includes('1 Flaky Test Candidate'), 'Single candidate title is correct');
  assert(singleOutput.summary.includes('| Test Name |'), 'Contains table header');
  assert(singleOutput.summary.includes('80.0%'), 'Contains confidence percentage');
  console.log();
  
  // Test 3: Multiple candidates with sorting
  console.log('Test 3: Multiple candidates with sorting');
  const multiCandidates = [
    createTestCandidate({ testName: 'test1', confidence: 0.9 }),
    createTestCandidate({ testName: 'test2', confidence: 0.6 }),
    createTestCandidate({ testName: 'test3', confidence: 0.4 })
  ];
  const multiOutput = renderCheckRunOutput(multiCandidates);
  assert(multiOutput.title.includes('3 Flaky Test Candidates'), 'Multiple candidates title is correct');
  
  const lines = multiOutput.summary.split('\n');
  const testLines = lines.filter(line => line.includes('`test'));
  assert(testLines[0].includes('test1'), 'Highest confidence test is first');
  assert(testLines[1].includes('test2'), 'Medium confidence test is second');
  assert(testLines[2].includes('test3'), 'Lowest confidence test is third');
  console.log();
  
  // Test 4: Action generation - empty with failures
  console.log('Test 4: Action generation');
  const emptyWithFailures = generateCheckRunActions([], true);
  assert(emptyWithFailures.length === 1, 'Empty with failures generates 1 action');
  assert(emptyWithFailures[0].identifier === 'rerun_failed', 'Suggests rerun_failed for failures');
  
  const emptyWithoutFailures = generateCheckRunActions([], false);
  assert(emptyWithoutFailures.length === 0, 'Empty without failures generates 0 actions');
  console.log();
  
  // Test 5: Action count constraint
  console.log('Test 5: Action count constraint');
  const manyTests = Array.from({ length: 50 }, (_, i) => 
    createTestCandidate({ testName: `test${i}`, confidence: 0.95 })
  );
  const manyActions = generateCheckRunActions(manyTests, true);
  assert(manyActions.length <= 3, 'Never exceeds 3 actions even with many tests');
  assert(manyActions.length >= 0, 'Always returns at least 0 actions');
  console.log();
  
  // Test 6: High confidence action prioritization
  console.log('Test 6: High confidence action prioritization');
  const highConfidenceTests = [
    createTestCandidate({ confidence: 0.9 }),
    createTestCandidate({ confidence: 0.85 })
  ];
  const highConfidenceActions = generateCheckRunActions(highConfidenceTests, true);
  assert(highConfidenceActions.length <= 3, 'High confidence respects action limit');
  assert(highConfidenceActions.some(a => a.identifier === 'rerun_failed'), 'Includes rerun_failed');
  assert(highConfidenceActions.some(a => a.identifier === 'quarantine'), 'Includes quarantine for high confidence');
  assert(highConfidenceActions.some(a => a.identifier === 'open_issue'), 'Includes open_issue');
  console.log();
  
  // Test 7: Markdown escaping
  console.log('Test 7: Markdown escaping');
  const specialCharsTest = createTestCandidate({
    testName: 'test_with_underscores.TestClass[param*value]'
  });
  const escapedOutput = renderCheckRunOutput([specialCharsTest]);
  assert(escapedOutput.summary.includes('\\['), 'Escapes square brackets');
  assert(escapedOutput.summary.includes('\\*'), 'Escapes asterisks');
  console.log();
  
  // Test 8: Large dataset handling
  console.log('Test 8: Large dataset handling');
  const largeTests = Array.from({ length: 100 }, (_, i) => 
    createTestCandidate({ testName: `test${i}`, confidence: Math.random() })
  );
  const largeOutput = renderCheckRunOutput(largeTests);
  assert(largeOutput.summary.includes('Showing top 10 of 100'), 'Limits display to top 10');
  const largeActions = generateCheckRunActions(largeTests, true);
  assert(largeActions.length <= 3, 'Large datasets still respect action limit');
  console.log();
  
  // Test 9: Edge cases - malformed data
  console.log('Test 9: Edge cases - malformed data');
  const malformedTest = createTestCandidate({
    testName: '',
    failCount: -1,
    rerunPassRate: 2.0,
    confidence: -0.5
  });
  
  try {
    const malformedOutput = renderCheckRunOutput([malformedTest]);
    const malformedActions = generateCheckRunActions([malformedTest], true);
    assert(malformedActions.length <= 3, 'Handles malformed data gracefully');
    assert(malformedOutput.title.length > 0, 'Produces valid output with malformed data');
  } catch (error) {
    assert(false, 'Should handle malformed data without throwing');
  }
  console.log();
  
  // Test 10: Output format consistency
  console.log('Test 10: Output format consistency');
  const consistentTests = [
    createTestCandidate({
      testName: 'com.example.IntegrationTest.testDatabaseConnection',
      failCount: 7,
      rerunPassRate: 0.65,
      lastFailedRun: '2024-01-15T10:30:00.000Z',
      confidence: 0.82,
      failurePattern: 'connection timeout'
    }),
    createTestCandidate({
      testName: 'com.example.UnitTest.testAsyncOperation',
      failCount: 3,
      rerunPassRate: 0.88,
      lastFailedRun: '2024-01-14T15:45:30.000Z',
      confidence: 0.58,
      failurePattern: 'race condition'
    })
  ];
  const consistentOutput = renderCheckRunOutput(consistentTests);
  assert(consistentOutput.title.includes('🔍 FlakeGuard Analysis'), 'Has consistent title format');
  assert(consistentOutput.summary.includes('## Flaky Test Candidates'), 'Has proper section headers');
  assert(consistentOutput.summary.includes('### What are flaky tests?'), 'Has explanation section');
  assert(consistentOutput.summary.includes('### Recommended Actions'), 'Has recommendations section');
  console.log();
  
  // Results
  console.log('='.repeat(60));
  console.log(`Test Results: ${passed} passed, ${failed} failed`);
  
  if (failed === 0) {
    console.log('✅ All tests passed! 🎉');
    console.log('\nKey Features Verified:');
    console.log('- ✅ Markdown output format consistency');
    console.log('- ✅ Action count validation (≤3 actions always)');
    console.log('- ✅ Edge case handling (malformed data)');
    console.log('- ✅ Proper test candidate sorting');
    console.log('- ✅ Special character escaping in markdown');
    console.log('- ✅ Large dataset performance');
    console.log('- ✅ Action prioritization logic');
    console.log('- ✅ Empty state handling');
    
    console.log('\n📦 Sample Output:');
    console.log('---');
    console.log('Title:', consistentOutput.title);
    console.log('\nSummary Preview:');
    console.log(consistentOutput.summary.substring(0, 300) + '...');
    
    const sampleActions = generateCheckRunActions(consistentTests, true);
    console.log('\nSample Actions:');
    sampleActions.forEach((action, i) => {
      console.log(`${i + 1}. ${action.label} - ${action.description}`);
    });
  } else {
    console.error('❌ Some tests failed');
    process.exit(1);
  }
}

// Run the tests
runTests();