/**
 * Check Runs Rendering System for FlakeGuard
 * 
 * Provides markdown rendering and GitHub Check Run management for flaky test detection:
 * - Generates comprehensive markdown summaries with flaky test candidates
 * - Creates exactly ≤3 requested actions (quarantine, rerun_failed, open_issue)
 * - Handles Check Run creation/updates with proper status transitions
 * - Integrates with existing Octokit utilities and flake detection systems
 * - Provides snapshot-testable output format consistency
 */

import type { Octokit } from '@octokit/rest';
import type { PrismaClient } from '@prisma/client';
import type {
  FlakeGuardCheckRun,
  CheckRunAction,
  CheckRunStatus,
  CheckRunConclusion,
  TestResult,
  ApiResponse,
} from './types.js';
import { GitHubAuthManager } from './auth.js';
import { logger } from '../utils/logger.js';
import { ErrorCode } from './api-spec.js';
import {
  CHECK_RUN_ACTION_CONFIGS,
  ERROR_MESSAGES,
} from './constants.js';

/**
 * Interface for test data used in check run rendering
 */
export interface TestCandidate {
  readonly testName: string;
  readonly failCount: number;
  readonly rerunPassRate: number;
  readonly lastFailedRun: string | null;
  readonly confidence: number;
  readonly failurePattern: string | null;
  readonly totalRuns: number;
}

/**
 * Check run output configuration
 */
export interface CheckRunOutput {
  readonly title: string;
  readonly summary: string;
  readonly text?: string;
}

/**
 * Check run action definition
 */
export interface CheckRunActionDef {
  readonly label: string;
  readonly description: string;
  readonly identifier: CheckRunAction;
}

/**
 * Parameters for check run creation/update
 */
export interface CheckRunParams {
  readonly owner: string;
  readonly repo: string;
  readonly name: string;
  readonly headSha: string;
  readonly installationId: number;
  readonly status?: CheckRunStatus;
  readonly conclusion?: CheckRunConclusion;
  readonly output?: CheckRunOutput;
  readonly actions?: readonly CheckRunActionDef[];
}

/**
 * Generate markdown summary for flaky test candidates
 * Shows top-N flaky candidates in a table format with key metrics
 */
export function renderCheckRunOutput(tests: readonly TestCandidate[]): CheckRunOutput {
  if (tests.length === 0) {
    return {
      title: '✅ FlakeGuard Analysis Complete',
      summary: 'No flaky test candidates detected in this run.\n\nAll tests appear to be stable based on historical analysis.',
    };
  }

  const title = `🔍 FlakeGuard Analysis: ${tests.length} Flaky Test Candidate${tests.length === 1 ? '' : 's'} Detected`;
  
  let summary = '## Flaky Test Candidates\n\n';
  summary += 'The following tests show patterns consistent with flaky behavior:\n\n';
  
  // Create markdown table with key metrics
  summary += '| Test Name | Fail Count | Rerun Pass Rate | Last Failed Run | Confidence |\n';
  summary += '|-----------|------------|-----------------|-----------------|------------|\n';
  
  // Show up to 10 top candidates, sorted by confidence then fail count
  const sortedTests = [...tests]
    .sort((a, b) => {
      if (b.confidence !== a.confidence) {
        return b.confidence - a.confidence;
      }
      return b.failCount - a.failCount;
    })
    .slice(0, 10);
    
  for (const test of sortedTests) {
    const passRate = `${(test.rerunPassRate * 100).toFixed(1)}%`;
    const confidence = `${(test.confidence * 100).toFixed(1)}%`;
    const lastRun = test.lastFailedRun 
      ? new Date(test.lastFailedRun).toLocaleDateString()
      : 'N/A';
    
    summary += `| \`${escapeMarkdown(test.testName)}\` | ${test.failCount} | ${passRate} | ${lastRun} | ${confidence} |\n`;
  }
  
  summary += '\n';
  
  if (tests.length > 10) {
    summary += `*Showing top 10 of ${tests.length} total candidates.*\n\n`;
  }
  
  // Add explanation section
  summary += '### What are flaky tests?\n\n';
  summary += 'Flaky tests are tests that exhibit both passing and failing results without changes to the code. ';
  summary += 'They can be caused by:\n\n';
  summary += '- **Race conditions** - Timing-dependent code execution\n';
  summary += '- **External dependencies** - Network calls, databases, file system\n';
  summary += '- **Resource contention** - Insufficient memory, CPU, or I/O\n';
  summary += '- **Non-deterministic behavior** - Random values, system time dependencies\n\n';
  
  // Add recommendations
  summary += '### Recommended Actions\n\n';
  summary += '1. **Quarantine** high-confidence flaky tests to prevent CI instability\n';
  summary += '2. **Rerun** failed jobs to confirm flaky behavior\n';
  summary += '3. **Open issues** to track and fix root causes\n\n';
  
  summary += '*This analysis is generated by FlakeGuard based on historical test execution data.*';
  
  return {
    title,
    summary,
  };
}

/**
 * Generate exactly ≤3 requested actions based on flaky test analysis
 * Actions are prioritized: quarantine, rerun_failed, open_issue
 */
export function generateCheckRunActions(
  tests: readonly TestCandidate[],
  hasFailures: boolean
): readonly CheckRunActionDef[] {
  const actions: CheckRunActionDef[] = [];
  
  // Always allow rerunning failed jobs if there are failures
  if (hasFailures && actions.length < 3) {
    actions.push({
      label: CHECK_RUN_ACTION_CONFIGS.rerun_failed.label,
      description: CHECK_RUN_ACTION_CONFIGS.rerun_failed.description,
      identifier: 'rerun_failed',
    });
  }
  
  // If we have high-confidence flaky tests, suggest quarantine
  const highConfidenceTests = tests.filter(t => t.confidence >= 0.7);
  if (highConfidenceTests.length > 0 && actions.length < 3) {
    actions.push({
      label: CHECK_RUN_ACTION_CONFIGS.quarantine.label,
      description: `Quarantine ${highConfidenceTests.length} high-confidence flaky test${highConfidenceTests.length === 1 ? '' : 's'}`,
      identifier: 'quarantine',
    });
  }
  
  // If we have any flaky tests, suggest opening an issue
  if (tests.length > 0 && actions.length < 3) {
    actions.push({
      label: CHECK_RUN_ACTION_CONFIGS.open_issue.label,
      description: `Create issue for ${tests.length} flaky test candidate${tests.length === 1 ? '' : 's'}`,
      identifier: 'open_issue',
    });
  }
  
  // Ensure we never exceed 3 actions (GitHub limit)
  return actions.slice(0, 3);
}

/**
 * Create or update a GitHub Check Run with proper status transitions
 * Ensures proper progression: queued → in_progress → completed
 */
export async function createOrUpdateCheckRun(
  authManager: GitHubAuthManager,
  params: CheckRunParams
): Promise<ApiResponse<FlakeGuardCheckRun>> {
  try {
    const client = await authManager.getInstallationClient(params.installationId);
    
    // Default to completed status if not specified
    const status = params.status || 'completed';
    const conclusion = params.conclusion || 'neutral';
    const completedAt = status === 'completed' ? new Date().toISOString() : undefined;
    
    logger.info('Creating GitHub check run', {
      owner: params.owner,
      repo: params.repo,
      name: params.name,
      headSha: params.headSha,
      status,
      conclusion,
    });
    
    const { data } = await client.rest.checks.create({
      owner: params.owner,
      repo: params.repo,
      name: params.name,
      head_sha: params.headSha,
      status: status as any,
      conclusion: status === 'completed' ? (conclusion as any) : undefined,
      started_at: new Date().toISOString(),
      completed_at: completedAt,
      output: params.output ? {
        title: params.output.title,
        summary: params.output.summary,
        text: params.output.text,
      } : undefined,
      actions: params.actions ? params.actions.map(action => ({
        label: action.label,
        description: action.description,
        identifier: action.identifier,
      })) : undefined,
    });
    
    const checkRun: FlakeGuardCheckRun = {
      id: data.id,
      name: data.name,
      headSha: data.head_sha,
      status: data.status as CheckRunStatus,
      conclusion: data.conclusion as CheckRunConclusion | null,
      startedAt: data.started_at,
      completedAt: data.completed_at,
      output: {
        title: data.output?.title || '',
        summary: data.output?.summary || '',
        text: data.output?.text || undefined,
      },
      actions: data.actions?.map(action => ({
        label: action.label,
        description: action.description,
        identifier: action.identifier as CheckRunAction,
      })) || [],
    };
    
    logger.info('GitHub check run created successfully', {
      checkRunId: data.id,
      name: data.name,
      status: data.status,
      conclusion: data.conclusion,
    });
    
    return { success: true, data: checkRun };
    
  } catch (error: any) {
    logger.error('Failed to create GitHub check run', {
      owner: params.owner,
      repo: params.repo,
      name: params.name,
      error: error.message,
      status: error.status,
    });
    
    return {
      success: false,
      error: {
        code: mapGitHubErrorCode(error),
        message: error.message || ERROR_MESSAGES.GITHUB_API_ERROR,
        details: { 
          status: error.status,
          response: error.response?.data,
        },
      },
    };
  }
}

/**
 * Update an existing GitHub Check Run
 * Handles status transitions and action updates
 */
export async function updateExistingCheckRun(
  authManager: GitHubAuthManager,
  owner: string,
  repo: string,
  checkRunId: number,
  installationId: number,
  updates: {
    readonly status?: CheckRunStatus;
    readonly conclusion?: CheckRunConclusion;
    readonly output?: CheckRunOutput;
    readonly actions?: readonly CheckRunActionDef[];
  }
): Promise<ApiResponse<FlakeGuardCheckRun>> {
  try {
    const client = await authManager.getInstallationClient(installationId);
    
    const completedAt = updates.status === 'completed' ? new Date().toISOString() : undefined;
    
    logger.info('Updating GitHub check run', {
      owner,
      repo,
      checkRunId,
      status: updates.status,
      conclusion: updates.conclusion,
    });
    
    const { data } = await client.rest.checks.update({
      owner,
      repo,
      check_run_id: checkRunId,
      status: updates.status as any,
      conclusion: updates.status === 'completed' ? (updates.conclusion as any) : undefined,
      completed_at: completedAt,
      output: updates.output ? {
        title: updates.output.title,
        summary: updates.output.summary,
        text: updates.output.text,
      } : undefined,
      actions: updates.actions ? updates.actions.map(action => ({
        label: action.label,
        description: action.description,
        identifier: action.identifier,
      })) : undefined,
    });
    
    const checkRun: FlakeGuardCheckRun = {
      id: data.id,
      name: data.name,
      headSha: data.head_sha,
      status: data.status as CheckRunStatus,
      conclusion: data.conclusion as CheckRunConclusion | null,
      startedAt: data.started_at,
      completedAt: data.completed_at,
      output: {
        title: data.output?.title || '',
        summary: data.output?.summary || '',
        text: data.output?.text || undefined,
      },
      actions: data.actions?.map(action => ({
        label: action.label,
        description: action.description,
        identifier: action.identifier as CheckRunAction,
      })) || [],
    };
    
    logger.info('GitHub check run updated successfully', {
      checkRunId,
      status: data.status,
      conclusion: data.conclusion,
    });
    
    return { success: true, data: checkRun };
    
  } catch (error: any) {
    logger.error('Failed to update GitHub check run', {
      owner,
      repo,
      checkRunId,
      error: error.message,
      status: error.status,
    });
    
    return {
      success: false,
      error: {
        code: mapGitHubErrorCode(error),
        message: error.message || ERROR_MESSAGES.GITHUB_API_ERROR,
        details: { 
          status: error.status,
          response: error.response?.data,
        },
      },
    };
  }
}

/**
 * Create a comprehensive FlakeGuard check run with analysis results
 */
export async function createFlakeGuardCheckRun(
  authManager: GitHubAuthManager,
  owner: string,
  repo: string,
  headSha: string,
  installationId: number,
  tests: readonly TestCandidate[],
  hasFailures: boolean = false
): Promise<ApiResponse<FlakeGuardCheckRun>> {
  const output = renderCheckRunOutput(tests);
  const actions = generateCheckRunActions(tests, hasFailures);
  
  // Determine conclusion based on findings
  let conclusion: CheckRunConclusion;
  if (tests.some(t => t.confidence >= 0.8)) {
    conclusion = 'action_required'; // High confidence flaky tests need attention
  } else if (tests.length > 0) {
    conclusion = 'neutral'; // Some candidates but not critical
  } else {
    conclusion = 'success'; // No flaky tests detected
  }
  
  return createOrUpdateCheckRun(authManager, {
    owner,
    repo,
    name: 'FlakeGuard Analysis',
    headSha,
    installationId,
    status: 'completed',
    conclusion,
    output,
    actions,
  });
}

/**
 * Convert test results from database into TestCandidate format
 */
export function convertToTestCandidates(
  prisma: PrismaClient,
  flakeDetections: Array<{
    testName: string;
    confidence: number;
    failureRate: number;
    totalRuns: number;
    historicalFailures: number;
    lastFailureAt: Date | null;
    failurePattern: string | null;
  }>
): TestCandidate[] {
  return flakeDetections.map(detection => {
    // Calculate rerun pass rate (approximate based on failure rate)
    const rerunPassRate = detection.totalRuns > 0 
      ? Math.max(0, 1 - (detection.failureRate * 1.2)) // Slightly conservative estimate
      : 0;
    
    return {
      testName: detection.testName,
      failCount: detection.historicalFailures,
      rerunPassRate,
      lastFailedRun: detection.lastFailureAt?.toISOString() || null,
      confidence: detection.confidence,
      failurePattern: detection.failurePattern,
      totalRuns: detection.totalRuns,
    };
  });
}

/**
 * Escape markdown special characters in test names
 */
function escapeMarkdown(text: string): string {
  return text.replace(/([\\`*_{}\[\]()#+\-.!])/g, '\\$1');
}

/**
 * Map GitHub API errors to internal error codes
 */
function mapGitHubErrorCode(error: any): string {
  if (error.status === 401) return ErrorCode.UNAUTHORIZED;
  if (error.status === 403) return ErrorCode.FORBIDDEN;
  if (error.status === 404) return ErrorCode.RESOURCE_NOT_FOUND;
  if (error.status === 422) return ErrorCode.VALIDATION_ERROR;
  if (error.status === 429) return ErrorCode.GITHUB_RATE_LIMITED;
  if (error.status >= 500) return ErrorCode.GITHUB_SERVICE_UNAVAILABLE;
  
  return ErrorCode.GITHUB_API_ERROR;
}