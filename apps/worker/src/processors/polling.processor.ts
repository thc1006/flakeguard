/**
 * Polling Processor
 * 
 * Periodically polls GitHub API for new workflow runs and enqueues\n * ingestion jobs when runs complete. Implements cursor-based pagination,\n * rate limiting, and repository discovery.\n */\n\nimport { Job, Queue } from 'bullmq';\nimport { PrismaClient } from '@prisma/client';\nimport { Octokit } from '@octokit/rest';\nimport { CronJob } from 'cron';\nimport { logger } from '../utils/logger.js';\nimport { connection } from '../utils/redis.js';\nimport { \n  recordJobCompletion,\n  recordGitHubApiCall,\n  githubRateLimitRemaining,\n  githubRateLimitReset\n} from '../utils/metrics.js';\nimport { \n  POLLING_CONFIG,\n  GITHUB_RATE_LIMITS,\n  QueueNames,\n  JobPriorities\n} from '@flakeguard/shared';\n\n// ============================================================================\n// Types and Interfaces\n// ============================================================================\n\nexport interface PollingJobData {\n  repositories?: Array<{\n    owner: string;\n    repo: string;\n    installationId: number;\n    lastPolledAt?: string;\n    active: boolean;\n  }>;\n  forceFullScan?: boolean;\n  batchSize?: number;\n  correlationId?: string;\n  triggeredBy: 'cron' | 'manual' | 'startup';\n}\n\nexport interface PollingResult {\n  success: boolean;\n  repositoriesPolled: number;\n  workflowRunsDiscovered: number;\n  newRunsQueued: number;\n  rateLimitRemaining: number;\n  processingTimeMs: number;\n  repositoryResults: RepositoryPollingResult[];\n  errors: string[];\n  warnings: string[];\n}\n\nexport interface RepositoryPollingResult {\n  repository: string;\n  runsDiscovered: number;\n  newRunsQueued: number;\n  lastRunDate?: string;\n  cursor?: string;\n  rateLimitHit: boolean;\n  error?: string;\n}\n\nexport interface WorkflowRunSummary {\n  id: number;\n  run_number: number;\n  status: string;\n  conclusion: string | null;\n  head_sha: string;\n  head_branch: string;\n  created_at: string;\n  updated_at: string;\n  repository: {\n    owner: { login: string };\n    name: string;\n  };\n}\n\nexport interface RepositoryContext {\n  owner: string;\n  repo: string;\n  installationId: number;\n  lastPolledAt?: Date;\n  cursor?: string;\n}\n\n// ============================================================================\n// Polling Manager\n// ============================================================================\n\nexport class PollingManager {\n  private prisma: PrismaClient;\n  private octokit?: Octokit;\n  private runsIngestQueue: Queue;\n  private runsAnalyzeQueue: Queue;\n  private cronJobs: Map<string, CronJob> = new Map();\n  private rateLimitBackoff = 0;\n  private lastRateLimitReset = 0;\n\n  constructor(\n    prisma: PrismaClient,\n    runsIngestQueue: Queue,\n    runsAnalyzeQueue: Queue,\n    octokit?: Octokit\n  ) {\n    this.prisma = prisma;\n    this.octokit = octokit;\n    this.runsIngestQueue = runsIngestQueue;\n    this.runsAnalyzeQueue = runsAnalyzeQueue;\n  }\n\n  /**\n   * Initialize polling system\n   */\n  async initialize(): Promise<void> {\n    logger.info('Initializing polling manager');\n    \n    if (POLLING_CONFIG.INTERVAL_MS > 0) {\n      // Set up cron job for periodic polling\n      const cronPattern = this.calculateCronPattern(POLLING_CONFIG.INTERVAL_MS);\n      \n      const pollingJob = new CronJob(\n        cronPattern,\n        () => this.triggerPolling('cron'),\n        null,\n        false, // Don't start immediately\n        'UTC'\n      );\n      \n      this.cronJobs.set('main_polling', pollingJob);\n      pollingJob.start();\n      \n      logger.info({ cronPattern, intervalMs: POLLING_CONFIG.INTERVAL_MS }, 'Polling cron job scheduled');\n    }\n    \n    // Run initial polling on startup\n    setTimeout(() => this.triggerPolling('startup'), 5000);\n  }\n\n  /**\n   * Shutdown polling system\n   */\n  async shutdown(): Promise<void> {\n    logger.info('Shutting down polling manager');\n    \n    for (const [name, job] of this.cronJobs) {\n      job.stop();\n      logger.debug({ jobName: name }, 'Stopped cron job');\n    }\n    \n    this.cronJobs.clear();\n  }\n\n  /**\n   * Trigger polling manually\n   */\n  async triggerPolling(triggeredBy: 'cron' | 'manual' | 'startup'): Promise<void> {\n    try {\n      // Check rate limit backoff\n      if (this.rateLimitBackoff > Date.now()) {\n        logger.warn({\n          backoffUntil: new Date(this.rateLimitBackoff).toISOString(),\n          triggeredBy\n        }, 'Skipping polling due to rate limit backoff');\n        return;\n      }\n\n      // Queue polling job\n      await this.runsIngestQueue.add(\n        'polling-job',\n        {\n          triggeredBy,\n          correlationId: `polling-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,\n          forceFullScan: triggeredBy === 'startup'\n        } as PollingJobData,\n        {\n          priority: JobPriorities.HIGH,\n          attempts: 3,\n          backoff: {\n            type: 'exponential',\n            delay: 5000\n          }\n        }\n      );\n      \n      logger.debug({ triggeredBy }, 'Polling job queued');\n      \n    } catch (error) {\n      logger.error({\n        error: error instanceof Error ? error.message : String(error),\n        triggeredBy\n      }, 'Failed to trigger polling');\n    }\n  }\n\n  /**\n   * Calculate cron pattern from interval\n   */\n  private calculateCronPattern(intervalMs: number): string {\n    const intervalMinutes = Math.floor(intervalMs / 60000);\n    \n    if (intervalMinutes < 60) {\n      return `*/${intervalMinutes} * * * *`; // Every N minutes\n    } else {\n      const intervalHours = Math.floor(intervalMinutes / 60);\n      return `0 */${intervalHours} * * *`; // Every N hours\n    }\n  }\n}\n\n// ============================================================================\n// Processor Implementation\n// ============================================================================\n\n/**\n * Create polling processor\n */\nexport function createPollingProcessor(\n  prisma: PrismaClient,\n  runsIngestQueue: Queue,\n  runsAnalyzeQueue: Queue,\n  octokit?: Octokit\n) {\n  return async function processPolling(\n    job: Job<PollingJobData>\n  ): Promise<PollingResult> {\n    const { data } = job;\n    const startTime = Date.now();\n    \n    logger.info({\n      jobId: job.id,\n      correlationId: data.correlationId,\n      triggeredBy: data.triggeredBy,\n      forceFullScan: data.forceFullScan\n    }, 'Processing polling job');\n\n    try {\n      // Update job progress\n      await job.updateProgress({\n        phase: 'discovering',\n        percentage: 10,\n        message: 'Discovering active repositories'\n      });\n\n      // Get GitHub client\n      const github = octokit || createMockGitHubClient();\n      \n      // Discover active repositories\n      const repositories = data.repositories || await discoverActiveRepositories(prisma, data.forceFullScan);\n      \n      if (repositories.length === 0) {\n        logger.info('No active repositories found for polling');\n        return createEmptyPollingResult(startTime);\n      }\n\n      logger.info({ repositoryCount: repositories.length }, 'Found repositories for polling');\n\n      // Update progress\n      await job.updateProgress({\n        phase: 'polling',\n        percentage: 20,\n        message: `Polling ${repositories.length} repositories`\n      });\n\n      // Poll repositories in batches\n      const batchSize = data.batchSize || POLLING_CONFIG.MAX_REPOSITORIES_PER_BATCH;\n      const repositoryResults: RepositoryPollingResult[] = [];\n      let totalRunsDiscovered = 0;\n      let totalNewRunsQueued = 0;\n      let currentRateLimitRemaining = GITHUB_RATE_LIMITS.PRIMARY_RATE_LIMIT;\n      \n      for (let i = 0; i < repositories.length; i += batchSize) {\n        const batch = repositories.slice(i, i + batchSize);\n        \n        // Update progress\n        const progressPercentage = 20 + ((i / repositories.length) * 60);\n        await job.updateProgress({\n          phase: 'polling',\n          percentage: progressPercentage,\n          message: `Processing batch ${Math.floor(i / batchSize) + 1} (${batch.length} repositories)`\n        });\n        \n        // Process batch with rate limiting\n        const batchResults = await processBatch(github, batch, data);\n        repositoryResults.push(...batchResults);\n        \n        // Aggregate results\n        for (const result of batchResults) {\n          totalRunsDiscovered += result.runsDiscovered;\n          totalNewRunsQueued += result.newRunsQueued;\n          \n          if (result.rateLimitHit) {\n            logger.warn({ repository: result.repository }, 'Rate limit hit during polling');\n            break; // Stop processing if we hit rate limits\n          }\n        }\n        \n        // Add delay between batches to respect rate limits\n        if (i + batchSize < repositories.length) {\n          await sleep(1000); // 1 second delay\n        }\n      }\n\n      // Update progress\n      await job.updateProgress({\n        phase: 'finalizing',\n        percentage: 90,\n        message: 'Updating repository polling status'\n      });\n\n      // Update repository polling timestamps\n      await updateRepositoryPollingStatus(prisma, repositoryResults);\n      \n      const processingTimeMs = Date.now() - startTime;\n      \n      // Final progress update\n      await job.updateProgress({\n        phase: 'complete',\n        percentage: 100,\n        message: 'Polling complete'\n      });\n\n      const result: PollingResult = {\n        success: true,\n        repositoriesPolled: repositories.length,\n        workflowRunsDiscovered: totalRunsDiscovered,\n        newRunsQueued: totalNewRunsQueued,\n        rateLimitRemaining: currentRateLimitRemaining,\n        processingTimeMs,\n        repositoryResults,\n        errors: [],\n        warnings: []\n      };\n\n      // Record job completion metrics\n      recordJobCompletion(QueueNames.POLLING, 'completed', 'normal', processingTimeMs);\n      \n      logger.info({\n        jobId: job.id,\n        repositoriesPolled: repositories.length,\n        workflowRunsDiscovered: totalRunsDiscovered,\n        newRunsQueued: totalNewRunsQueued,\n        processingTimeMs\n      }, 'Polling completed successfully');\n\n      return result;\n\n    } catch (error) {\n      const processingTimeMs = Date.now() - startTime;\n      const errorMessage = error instanceof Error ? error.message : String(error);\n      \n      recordJobCompletion(QueueNames.POLLING, 'failed', 'normal', processingTimeMs, 'polling_error');\n      \n      logger.error({\n        jobId: job.id,\n        correlationId: data.correlationId,\n        error: errorMessage,\n        stack: error instanceof Error ? error.stack : undefined,\n        processingTimeMs\n      }, 'Polling failed');\n\n      throw error;\n    }\n  };\n}\n\n// ============================================================================\n// Repository Discovery\n// ============================================================================\n\n/**\n * Discover active repositories to poll\n */\nasync function discoverActiveRepositories(\n  prisma: PrismaClient,\n  forceFullScan = false\n): Promise<Array<{ owner: string; repo: string; installationId: number; lastPolledAt?: string; active: boolean }>> {\n  try {\n    // Get repositories from database (would be enhanced with GitHub App installations)\n    const repositories = await prisma.repository.findMany({\n      where: {\n        active: true,\n        ...(forceFullScan ? {} : {\n          OR: [\n            { lastPolledAt: null },\n            {\n              lastPolledAt: {\n                lte: new Date(Date.now() - POLLING_CONFIG.INTERVAL_MS)\n              }\n            }\n          ]\n        })\n      },\n      select: {\n        owner: true,\n        name: true,\n        installationId: true,\n        lastPolledAt: true,\n        active: true\n      },\n      orderBy: {\n        lastPolledAt: 'asc' // Poll oldest first\n      },\n      take: POLLING_CONFIG.MAX_REPOSITORIES_PER_BATCH * 3 // Allow for some buffer\n    });\n    \n    return repositories.map(repo => ({\n      owner: repo.owner,\n      repo: repo.name,\n      installationId: repo.installationId || 0,\n      lastPolledAt: repo.lastPolledAt?.toISOString(),\n      active: repo.active\n    }));\n    \n  } catch (error) {\n    logger.error({\n      error: error instanceof Error ? error.message : String(error)\n    }, 'Failed to discover active repositories');\n    return [];\n  }\n}\n\n// ============================================================================\n// Batch Processing\n// ============================================================================\n\n/**\n * Process a batch of repositories\n */\nasync function processBatch(\n  github: Octokit,\n  repositories: Array<{ owner: string; repo: string; installationId: number; lastPolledAt?: string }>,\n  jobData: PollingJobData\n): Promise<RepositoryPollingResult[]> {\n  const results: RepositoryPollingResult[] = [];\n  \n  for (const repo of repositories) {\n    try {\n      const result = await pollRepository(github, repo, jobData);\n      results.push(result);\n      \n      // Stop if rate limit hit\n      if (result.rateLimitHit) {\n        break;\n      }\n      \n    } catch (error) {\n      const errorMessage = error instanceof Error ? error.message : String(error);\n      logger.error({\n        repository: `${repo.owner}/${repo.repo}`,\n        error: errorMessage\n      }, 'Failed to poll repository');\n      \n      results.push({\n        repository: `${repo.owner}/${repo.repo}`,\n        runsDiscovered: 0,\n        newRunsQueued: 0,\n        rateLimitHit: false,\n        error: errorMessage\n      });\n    }\n  }\n  \n  return results;\n}\n\n/**\n * Poll a single repository for workflow runs\n */\nasync function pollRepository(\n  github: Octokit,\n  repo: { owner: string; repo: string; installationId: number; lastPolledAt?: string },\n  jobData: PollingJobData\n): Promise<RepositoryPollingResult> {\n  const startTime = Date.now();\n  let runsDiscovered = 0;\n  let newRunsQueued = 0;\n  let rateLimitHit = false;\n  let cursor: string | undefined;\n  let lastRunDate: string | undefined;\n  \n  try {\n    // Calculate lookback time\n    const lookbackTime = repo.lastPolledAt \n      ? new Date(repo.lastPolledAt)\n      : new Date(Date.now() - POLLING_CONFIG.WORKFLOW_RUN_LOOKBACK_HOURS * 60 * 60 * 1000);\n    \n    logger.debug({\n      repository: `${repo.owner}/${repo.repo}`,\n      lookbackTime: lookbackTime.toISOString(),\n      lastPolledAt: repo.lastPolledAt\n    }, 'Polling repository for workflow runs');\n    \n    let page = 1;\n    let hasMore = true;\n    \n    while (hasMore && page <= 10) { // Limit to 10 pages to avoid runaway\n      const response = await github.rest.actions.listWorkflowRunsForRepo({\n        owner: repo.owner,\n        repo: repo.repo,\n        status: 'completed',\n        per_page: POLLING_CONFIG.CURSOR_PAGINATION_LIMIT,\n        page,\n        created: `>=${lookbackTime.toISOString()}`\n      });\n      \n      const duration = Date.now() - startTime;\n      recordGitHubApiCall(\n        'listWorkflowRunsForRepo',\n        'GET',\n        response.status,\n        duration,\n        response.headers['x-ratelimit-remaining'] ? parseInt(response.headers['x-ratelimit-remaining'] as string) : undefined,\n        response.headers['x-ratelimit-reset'] ? parseInt(response.headers['x-ratelimit-reset'] as string) : undefined\n      );\n      \n      const runs = response.data.workflow_runs;\n      runsDiscovered += runs.length;\n      \n      // Check rate limits\n      if (response.headers['x-ratelimit-remaining']) {\n        const remaining = parseInt(response.headers['x-ratelimit-remaining'] as string);\n        githubRateLimitRemaining.set({ rate_limit_type: 'primary' }, remaining);\n        \n        if (remaining < 100) {\n          logger.warn({\n            repository: `${repo.owner}/${repo.repo}`,\n            rateLimitRemaining: remaining\n          }, 'Approaching GitHub rate limit');\n          \n          if (remaining < 10) {\n            rateLimitHit = true;\n            hasMore = false;\n            break;\n          }\n        }\n      }\n      \n      if (response.headers['x-ratelimit-reset']) {\n        const resetTime = parseInt(response.headers['x-ratelimit-reset'] as string);\n        githubRateLimitReset.set({ rate_limit_type: 'primary' }, resetTime);\n      }\n      \n      // Process completed runs\n      for (const run of runs) {\n        if (run.status === 'completed' && run.conclusion) {\n          // Check if we've already processed this run\n          const alreadyProcessed = await checkRunAlreadyProcessed(repo, run.id);\n          \n          if (!alreadyProcessed) {\n            await enqueueIngestionJob(repo, run, jobData.correlationId);\n            newRunsQueued++;\n          }\n          \n          // Track latest run date\n          if (!lastRunDate || run.created_at > lastRunDate) {\n            lastRunDate = run.created_at;\n          }\n        }\n      }\n      \n      // Check if there are more pages\n      hasMore = runs.length === POLLING_CONFIG.CURSOR_PAGINATION_LIMIT;\n      page++;\n      \n      // Add small delay between pages\n      if (hasMore) {\n        await sleep(200);\n      }\n    }\n    \n    logger.debug({\n      repository: `${repo.owner}/${repo.repo}`,\n      runsDiscovered,\n      newRunsQueued,\n      pages: page - 1\n    }, 'Repository polling completed');\n    \n    return {\n      repository: `${repo.owner}/${repo.repo}`,\n      runsDiscovered,\n      newRunsQueued,\n      lastRunDate,\n      cursor,\n      rateLimitHit\n    };\n    \n  } catch (error) {\n    const duration = Date.now() - startTime;\n    \n    // Handle rate limiting\n    if (error instanceof Error && 'status' in error && error.status === 403) {\n      logger.warn({\n        repository: `${repo.owner}/${repo.repo}`,\n        error: error.message\n      }, 'Rate limited while polling repository');\n      \n      rateLimitHit = true;\n      recordGitHubApiCall('listWorkflowRunsForRepo', 'GET', 403, duration);\n    } else {\n      recordGitHubApiCall('listWorkflowRunsForRepo', 'GET', 500, duration);\n    }\n    \n    throw error;\n  }\n}\n\n// ============================================================================\n// Job Enqueueing\n// ============================================================================\n\n/**\n * Check if workflow run has already been processed\n */\nasync function checkRunAlreadyProcessed(\n  repo: { owner: string; repo: string },\n  runId: number\n): Promise<boolean> {\n  try {\n    // Simple check - would be enhanced with actual database lookup\n    // For now, use Redis to track processed runs\n    const key = `processed_runs:${repo.owner}:${repo.repo}:${runId}`;\n    const result = await connection.get(key);\n    return result !== null;\n    \n  } catch (error) {\n    logger.warn({\n      repository: `${repo.owner}/${repo.repo}`,\n      runId,\n      error: error instanceof Error ? error.message : String(error)\n    }, 'Failed to check if run already processed');\n    return false; // Assume not processed on error\n  }\n}\n\n/**\n * Enqueue ingestion job for workflow run\n */\nasync function enqueueIngestionJob(\n  repo: { owner: string; repo: string; installationId: number },\n  run: WorkflowRunSummary,\n  correlationId?: string\n): Promise<void> {\n  try {\n    // Create ingestion job\n    const jobData = {\n      workflowRunId: run.id,\n      repository: {\n        owner: repo.owner,\n        repo: repo.repo,\n        installationId: repo.installationId\n      },\n      correlationId,\n      priority: 'normal' as const,\n      triggeredBy: 'polling' as const,\n      metadata: {\n        runStatus: run.status,\n        conclusion: run.conclusion,\n        headSha: run.head_sha,\n        headBranch: run.head_branch,\n        runNumber: run.run_number\n      }\n    };\n    \n    // Add to ingestion queue with deduplication\n    const dedupeKey = `${repo.owner}:${repo.repo}:${run.id}`;\n    \n    const queue = new Queue(QueueNames.RUNS_INGEST, { connection });\n    await queue.add(\n      'runs-ingest',\n      jobData,\n      {\n        priority: JobPriorities.NORMAL,\n        attempts: 3,\n        backoff: {\n          type: 'exponential',\n          delay: 5000\n        },\n        removeOnComplete: 100,\n        removeOnFail: 50,\n        jobId: dedupeKey // Use as dedup key\n      }\n    );\n    \n    // Mark as processed\n    const processedKey = `processed_runs:${repo.owner}:${repo.repo}:${run.id}`;\n    await connection.setex(processedKey, 86400 * 7, '1'); // 7 day expiry\n    \n    logger.debug({\n      repository: `${repo.owner}/${repo.repo}`,\n      workflowRunId: run.id,\n      runNumber: run.run_number,\n      conclusion: run.conclusion\n    }, 'Enqueued ingestion job');\n    \n  } catch (error) {\n    logger.error({\n      repository: `${repo.owner}/${repo.repo}`,\n      workflowRunId: run.id,\n      error: error instanceof Error ? error.message : String(error)\n    }, 'Failed to enqueue ingestion job');\n    throw error;\n  }\n}\n\n// ============================================================================\n// Database Updates\n// ============================================================================\n\n/**\n * Update repository polling status\n */\nasync function updateRepositoryPollingStatus(\n  prisma: PrismaClient,\n  results: RepositoryPollingResult[]\n): Promise<void> {\n  try {\n    for (const result of results) {\n      const [owner, repo] = result.repository.split('/');\n      \n      await prisma.repository.upsert({\n        where: {\n          owner_name: {\n            owner,\n            name: repo\n          }\n        },\n        update: {\n          lastPolledAt: new Date(),\n          lastRunDate: result.lastRunDate ? new Date(result.lastRunDate) : undefined,\n          updatedAt: new Date()\n        },\n        create: {\n          owner,\n          name: repo,\n          active: true,\n          lastPolledAt: new Date(),\n          lastRunDate: result.lastRunDate ? new Date(result.lastRunDate) : undefined,\n          createdAt: new Date(),\n          updatedAt: new Date()\n        }\n      });\n    }\n    \n    logger.debug({ repositoriesUpdated: results.length }, 'Updated repository polling status');\n    \n  } catch (error) {\n    logger.error({\n      error: error instanceof Error ? error.message : String(error)\n    }, 'Failed to update repository polling status');\n  }\n}\n\n// ============================================================================\n// Utility Functions\n// ============================================================================\n\n/**\n * Sleep for specified milliseconds\n */\nfunction sleep(ms: number): Promise<void> {\n  return new Promise(resolve => setTimeout(resolve, ms));\n}\n\n/**\n * Create empty polling result\n */\nfunction createEmptyPollingResult(startTime: number): PollingResult {\n  return {\n    success: true,\n    repositoriesPolled: 0,\n    workflowRunsDiscovered: 0,\n    newRunsQueued: 0,\n    rateLimitRemaining: GITHUB_RATE_LIMITS.PRIMARY_RATE_LIMIT,\n    processingTimeMs: Date.now() - startTime,\n    repositoryResults: [],\n    errors: [],\n    warnings: []\n  };\n}\n\n/**\n * Create mock GitHub client for testing\n */\nfunction createMockGitHubClient(): Octokit {\n  return {\n    rest: {\n      actions: {\n        listWorkflowRunsForRepo: async () => ({\n          data: { workflow_runs: [] },\n          status: 200,\n          headers: {\n            'x-ratelimit-remaining': '5000',\n            'x-ratelimit-reset': String(Math.floor(Date.now() / 1000) + 3600)\n          }\n        })\n      }\n    }\n  } as any;\n}\n\n// ============================================================================\n// Export Processor Factory and Manager\n// ============================================================================\n\n/**\n * Factory function for polling processor\n */\nexport function pollingProcessor(\n  prisma: PrismaClient,\n  runsIngestQueue: Queue,\n  runsAnalyzeQueue: Queue,\n  octokit?: Octokit\n) {\n  const processor = createPollingProcessor(prisma, runsIngestQueue, runsAnalyzeQueue, octokit);\n  \n  return async (job: Job<PollingJobData>): Promise<PollingResult> => {\n    return processor(job);\n  };\n}\n\n/**\n * Create and return polling manager instance\n */\nexport function createPollingManager(\n  prisma: PrismaClient,\n  runsIngestQueue: Queue,\n  runsAnalyzeQueue: Queue,\n  octokit?: Octokit\n): PollingManager {\n  return new PollingManager(prisma, runsIngestQueue, runsAnalyzeQueue, octokit);\n}\n\nexport default pollingProcessor;"