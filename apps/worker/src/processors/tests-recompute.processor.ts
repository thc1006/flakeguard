/* eslint-disable @typescript-eslint/no-unused-vars, import/order */

/**
 * Tests Recompute Processor
 * 
 * Recalculates flakiness scores for specific test patterns or repositories,
 * useful for backfilling analysis after configuration changes or for
 * periodic batch recomputation of historical data.
 */

// Unused imports removed to fix compilation

// ============================================================================
// Types and Interfaces
// ============================================================================\n\nexport interface TestsRecomputeJobData {\n  repository: {\n    owner: string;\n    repo: string;\n  };\n  recomputeScope: {\n    type: 'all' | 'test_pattern' | 'class_pattern' | 'specific_tests';\n    patterns?: string[]; // For pattern-based recompute\n    testIdentifiers?: Array<{ // For specific tests\n      className: string;\n      testName: string;\n    }>;\n    lookbackDays?: number;\n    minRunsThreshold?: number;\n  };\n  correlationId?: string;\n  priority: 'low' | 'normal' | 'high' | 'critical';\n  triggeredBy?: 'schedule' | 'config_change' | 'manual' | 'data_migration';\n  options?: {\n    batchSize?: number;\n    includeHistorical?: boolean;\n    updateQuarantineStatus?: boolean;\n    notifyOnCompletion?: boolean;\n  };\n}\n\nexport interface RecomputeResult {\n  success: boolean;\n  recomputedTests: number;\n  updatedFlakyTests: number;\n  quarantinedTests: number;\n  unquarantinedTests: number;\n  totalExecutionsAnalyzed: number;\n  processingTimeMs: number;\n  batchResults: BatchResult[];\n  errors: string[];\n  warnings: string[];\n  summary: RecomputeSummary;\n}\n\nexport interface BatchResult {\n  batchNumber: number;\n  testsProcessed: number;\n  newFlakyTests: number;\n  improvedTests: number;\n  processingTimeMs: number;\n  errors: string[];\n}\n\nexport interface RecomputeSummary {\n  totalTestsAnalyzed: number;\n  previousFlakyCount: number;\n  newFlakyCount: number;\n  averageFlakinessScore: number;\n  mostFlakyTest?: {\n    className: string;\n    testName: string;\n    score: number;\n  };\n  leastFlakyTest?: {\n    className: string;\n    testName: string;\n    score: number;\n  };\n  patternsDetected: Record<string, number>;\n  severityDistribution: Record<string, number>;\n}\n\nexport interface TestRecomputeData {\n  className: string;\n  testName: string;\n  executions: TestExecution[];\n  previousScore?: number;\n  previousSeverity?: string;\n}\n\nexport interface TestExecution {\n  workflowRunId: number;\n  status: 'passed' | 'failed' | 'error' | 'skipped';\n  executionTime: number;\n  timestamp: Date;\n  branch: string;\n  commitSha: string;\n  runNumber: number;\n  failureMessage?: string;\n  errorMessage?: string;\n}\n\n// ============================================================================\n// Processor Implementation\n// ============================================================================\n\n/**\n * Create tests recompute processor\n */\nexport function createTestsRecomputeProcessor(prisma: PrismaClient) {\n  return async function processTestsRecompute(\n    job: Job<TestsRecomputeJobData>\n  ): Promise<RecomputeResult> {\n    const { data } = job;\n    const startTime = Date.now();\n    \n    logger.info({\n      jobId: job.id,\n      repository: `${data.repository.owner}/${data.repository.repo}`,\n      scope: data.recomputeScope.type,\n      correlationId: data.correlationId,\n      priority: data.priority,\n      triggeredBy: data.triggeredBy\n    }, 'Processing tests recompute job');\n\n    try {\n      // Update job progress\n      await job.updateProgress({\n        phase: 'discovering',\n        percentage: 5,\n        message: 'Discovering tests to recompute'\n      });\n\n      // Load test data based on scope\n      const testDataList = await loadTestsForRecompute(prisma, data);\n      \n      if (testDataList.length === 0) {\n        logger.info({\n          repository: `${data.repository.owner}/${data.repository.repo}`,\n          scope: data.recomputeScope.type\n        }, 'No tests found for recompute');\n        \n        return createEmptyRecomputeResult(startTime);\n      }\n\n      logger.info({\n        testsToRecompute: testDataList.length,\n        scope: data.recomputeScope.type\n      }, 'Found tests for recompute');\n\n      // Update progress\n      await job.updateProgress({\n        phase: 'processing',\n        percentage: 15,\n        message: `Processing ${testDataList.length} tests`\n      });\n\n      // Process tests in batches\n      const batchSize = data.options?.batchSize || 50;\n      const batchResults: BatchResult[] = [];\n      let totalRecomputed = 0;\n      let totalUpdatedFlaky = 0;\n      let totalQuarantined = 0;\n      let totalUnquarantined = 0;\n      let totalExecutions = 0;\n      \n      for (let i = 0; i < testDataList.length; i += batchSize) {\n        const batchNumber = Math.floor(i / batchSize) + 1;\n        const batch = testDataList.slice(i, i + batchSize);\n        \n        // Update progress\n        const progressPercentage = 15 + ((i / testDataList.length) * 70);\n        await job.updateProgress({\n          phase: 'processing',\n          percentage: progressPercentage,\n          message: `Processing batch ${batchNumber} (${batch.length} tests)`\n        });\n        \n        const batchResult = await processBatch(prisma, data, batch, batchNumber);\n        batchResults.push(batchResult);\n        \n        totalRecomputed += batchResult.testsProcessed;\n        totalUpdatedFlaky += batchResult.newFlakyTests;\n        // Additional counters would be added based on batch processing results\n        \n        // Count executions\n        totalExecutions += batch.reduce((sum, test) => sum + test.executions.length, 0);\n        \n        logger.debug({\n          batchNumber,\n          testsProcessed: batchResult.testsProcessed,\n          newFlakyTests: batchResult.newFlakyTests,\n          processingTime: batchResult.processingTimeMs\n        }, 'Batch processing completed');\n      }\n\n      // Update progress\n      await job.updateProgress({\n        phase: 'finalizing',\n        percentage: 90,\n        message: 'Generating summary and updating quarantine status'\n      });\n\n      // Generate comprehensive summary\n      const summary = await generateRecomputeSummary(prisma, data, batchResults);\n      \n      // Update quarantine status if requested\n      if (data.options?.updateQuarantineStatus) {\n        const quarantineResult = await updateQuarantineStatus(prisma, data.repository);\n        totalQuarantined = quarantineResult.quarantined;\n        totalUnquarantined = quarantineResult.unquarantined;\n      }\n\n      const processingTimeMs = Date.now() - startTime;\n      \n      // Final progress update\n      await job.updateProgress({\n        phase: 'complete',\n        percentage: 100,\n        message: 'Recompute complete'\n      });\n\n      const result: RecomputeResult = {\n        success: true,\n        recomputedTests: totalRecomputed,\n        updatedFlakyTests: totalUpdatedFlaky,\n        quarantinedTests: totalQuarantined,\n        unquarantinedTests: totalUnquarantined,\n        totalExecutionsAnalyzed: totalExecutions,\n        processingTimeMs,\n        batchResults,\n        errors: [],\n        warnings: [],\n        summary\n      };\n\n      // Record metrics\n      recordFlakinessAnalysis(\n        `${data.repository.owner}/${data.repository.repo}`,\n        totalRecomputed,\n        totalUpdatedFlaky,\n        summary.averageFlakinessScore,\n        processingTimeMs\n      );\n      \n      recordJobCompletion(QueueNames.TESTS_RECOMPUTE, 'completed', data.priority, processingTimeMs);\n      \n      logger.info({\n        jobId: job.id,\n        repository: `${data.repository.owner}/${data.repository.repo}`,\n        recomputedTests: totalRecomputed,\n        updatedFlakyTests: totalUpdatedFlaky,\n        quarantinedTests: totalQuarantined,\n        processingTimeMs\n      }, 'Tests recompute completed successfully');\n\n      return result;\n\n    } catch (error) {\n      const processingTimeMs = Date.now() - startTime;\n      const errorMessage = error instanceof Error ? error.message : String(error);\n      \n      recordJobCompletion(QueueNames.TESTS_RECOMPUTE, 'failed', data.priority, processingTimeMs, 'recompute_error');\n      \n      logger.error({\n        jobId: job.id,\n        repository: `${data.repository.owner}/${data.repository.repo}`,\n        error: errorMessage,\n        stack: error instanceof Error ? error.stack : undefined,\n        processingTimeMs\n      }, 'Tests recompute failed');\n\n      throw error;\n    }\n  };\n}\n\n// ============================================================================\n// Data Loading Functions\n// ============================================================================\n\n/**\n * Load tests for recompute based on scope\n */\nasync function loadTestsForRecompute(\n  prisma: PrismaClient,\n  data: TestsRecomputeJobData\n): Promise<TestRecomputeData[]> {\n  const lookbackDays = data.recomputeScope.lookbackDays || FLAKINESS_CONFIG.ANALYSIS_WINDOW_DAYS;\n  const minRuns = data.recomputeScope.minRunsThreshold || FLAKINESS_CONFIG.MIN_RUNS_FOR_ANALYSIS;\n  \n  const cutoffDate = new Date();\n  cutoffDate.setDate(cutoffDate.getDate() - lookbackDays);\n  \n  try {\n    let whereClause: any = {\n      testSuite: {\n        workflowRun: {\n          repositoryOwner: data.repository.owner,\n          repositoryName: data.repository.repo,\n          createdAt: {\n            gte: cutoffDate\n          }\n        }\n      }\n    };\n    \n    // Apply scope-specific filters\n    switch (data.recomputeScope.type) {\n      case 'test_pattern':\n        if (data.recomputeScope.patterns && data.recomputeScope.patterns.length > 0) {\n          whereClause.OR = data.recomputeScope.patterns.map(pattern => ({\n            name: { contains: pattern, mode: 'insensitive' }\n          }));\n        }\n        break;\n        \n      case 'class_pattern':\n        if (data.recomputeScope.patterns && data.recomputeScope.patterns.length > 0) {\n          whereClause.OR = data.recomputeScope.patterns.map(pattern => ({\n            className: { contains: pattern, mode: 'insensitive' }\n          }));\n        }\n        break;\n        \n      case 'specific_tests':\n        if (data.recomputeScope.testIdentifiers && data.recomputeScope.testIdentifiers.length > 0) {\n          whereClause.OR = data.recomputeScope.testIdentifiers.map(test => ({\n            AND: [\n              { className: test.className },\n              { name: test.testName }\n            ]\n          }));\n        }\n        break;\n        \n      case 'all':\n        // No additional filters\n        break;\n    }\n    \n    // Load test cases with execution history\n    const testCasesWithHistory = await prisma.testCase.findMany({\n      where: whereClause,\n      include: {\n        testSuite: {\n          include: {\n            workflowRun: true\n          }\n        }\n      },\n      orderBy: [\n        { className: 'asc' },\n        { name: 'asc' },\n        { createdAt: 'desc' }\n      ]\n    });\n    \n    // Load previous flaky test records for comparison\n    const previousFlakyTests = await prisma.flakyTest.findMany({\n      where: {\n        repositoryOwner: data.repository.owner,\n        repositoryName: data.repository.repo\n      }\n    });\n    \n    const previousFlakyMap = new Map(\n      previousFlakyTests.map(t => [`${t.className}#${t.testName}`, t])\n    );\n    \n    // Group by test and build execution history\n    const testDataMap = new Map<string, TestRecomputeData>();\n    \n    for (const testCase of testCasesWithHistory) {\n      const testKey = `${testCase.className}#${testCase.name}`;\n      \n      if (!testDataMap.has(testKey)) {\n        const previousFlaky = previousFlakyMap.get(testKey);\n        testDataMap.set(testKey, {\n          className: testCase.className,\n          testName: testCase.name,\n          executions: [],\n          previousScore: previousFlaky?.flakinessScore,\n          previousSeverity: previousFlaky?.severity\n        });\n      }\n      \n      const testData = testDataMap.get(testKey)!;\n      testData.executions.push({\n        workflowRunId: testCase.testSuite.workflowRunId,\n        status: testCase.status,\n        executionTime: testCase.time,\n        timestamp: testCase.createdAt,\n        branch: testCase.testSuite.workflowRun.headBranch,\n        commitSha: testCase.testSuite.workflowRun.headSha,\n        runNumber: testCase.testSuite.workflowRun.runNumber,\n        failureMessage: testCase.failureMessage || undefined,\n        errorMessage: testCase.errorMessage || undefined\n      });\n    }\n    \n    // Filter tests with sufficient execution history\n    const result = Array.from(testDataMap.values())\n      .filter(testData => testData.executions.length >= minRuns);\n    \n    logger.debug({\n      totalTestCases: testCasesWithHistory.length,\n      uniqueTests: testDataMap.size,\n      testsWithSufficientHistory: result.length,\n      minRuns,\n      lookbackDays,\n      scope: data.recomputeScope.type\n    }, 'Loaded tests for recompute');\n    \n    return result;\n    \n  } catch (error) {\n    logger.error({\n      repository: `${data.repository.owner}/${data.repository.repo}`,\n      error: error instanceof Error ? error.message : String(error)\n    }, 'Failed to load tests for recompute');\n    throw error;\n  }\n}\n\n// ============================================================================\n// Batch Processing Functions\n// ============================================================================\n\n/**\n * Process a batch of tests\n */\nasync function processBatch(\n  prisma: PrismaClient,\n  jobData: TestsRecomputeJobData,\n  batch: TestRecomputeData[],\n  batchNumber: number\n): Promise<BatchResult> {\n  const batchStartTime = Date.now();\n  const errors: string[] = [];\n  let testsProcessed = 0;\n  let newFlakyTests = 0;\n  let improvedTests = 0;\n  \n  try {\n    // Process tests in this batch\n    for (const testData of batch) {\n      try {\n        // Recompute flakiness score\n        const analysisResult = await recomputeTestFlakiness(testData);\n        \n        // Store updated results\n        await storeRecomputedResult(prisma, jobData.repository, testData, analysisResult);\n        \n        testsProcessed++;\n        \n        // Check if this is a new flaky test\n        if (analysisResult.isFlaky && (!testData.previousScore || testData.previousScore < FLAKINESS_CONFIG.FLAKINESS_THRESHOLD)) {\n          newFlakyTests++;\n        }\n        \n        // Check if this test improved\n        if (testData.previousScore && testData.previousScore >= FLAKINESS_CONFIG.FLAKINESS_THRESHOLD && !analysisResult.isFlaky) {\n          improvedTests++;\n        }\n        \n      } catch (testError) {\n        const errorMessage = `Failed to recompute ${testData.className}.${testData.testName}: ${testError instanceof Error ? testError.message : String(testError)}`;\n        logger.error({ testData: testData.className, error: errorMessage }, 'Test recompute failed');\n        errors.push(errorMessage);\n      }\n    }\n    \n  } catch (batchError) {\n    const errorMessage = `Batch ${batchNumber} processing failed: ${batchError instanceof Error ? batchError.message : String(batchError)}`;\n    logger.error({ batchNumber, error: errorMessage }, 'Batch processing failed');\n    errors.push(errorMessage);\n  }\n  \n  return {\n    batchNumber,\n    testsProcessed,\n    newFlakyTests,\n    improvedTests,\n    processingTimeMs: Date.now() - batchStartTime,\n    errors\n  };\n}\n\n/**\n * Recompute flakiness for a single test\n */\nasync function recomputeTestFlakiness(testData: TestRecomputeData) {\n  const executions = testData.executions;\n  const totalRuns = executions.length;\n  \n  // Count outcomes\n  const failures = executions.filter(e => e.status === 'failed' || e.status === 'error').length;\n  const successes = executions.filter(e => e.status === 'passed').length;\n  const skipped = executions.filter(e => e.status === 'skipped').length;\n  \n  // Calculate basic metrics\n  const successRate = successes / (totalRuns - skipped);\n  const failureRate = failures / (totalRuns - skipped);\n  \n  // Calculate flakiness score (reusing logic from runs-analyze processor)\n  let flakinessScore = 0;\n  \n  // Factor 1: Failure rate\n  flakinessScore += failureRate * 0.4;\n  \n  // Factor 2: Inconsistency penalty\n  const inconsistencyPenalty = calculateInconsistencyPenalty(executions);\n  flakinessScore += inconsistencyPenalty * 0.3;\n  \n  // Factor 3: Recency factor\n  const recencyFactor = calculateRecencyFactor(executions);\n  flakinessScore += recencyFactor * 0.2;\n  \n  // Factor 4: Branch diversity\n  const branchDiversityFactor = calculateBranchDiversityFactor(executions);\n  flakinessScore += branchDiversityFactor * 0.1;\n  \n  // Normalize to 0-1 range\n  flakinessScore = Math.min(flakinessScore, 1.0);\n  \n  // Count recent failures\n  const recentExecutions = executions.slice(0, Math.min(10, executions.length));\n  const recentFailures = recentExecutions.filter(e => e.status === 'failed' || e.status === 'error').length;\n  \n  // Detect pattern\n  const pattern = detectFlakinessPattern(executions);\n  \n  // Determine severity\n  const severity = determineSeverity(flakinessScore, recentFailures, totalRuns);\n  \n  // Check if test is considered flaky\n  const isFlaky = flakinessScore >= FLAKINESS_CONFIG.FLAKINESS_THRESHOLD;\n  \n  // Get affected branches\n  const affectedBranches = Array.from(new Set(\n    executions\n      .filter(e => e.status === 'failed' || e.status === 'error')\n      .map(e => e.branch)\n  ));\n  \n  return {\n    flakinessScore,\n    totalRuns,\n    failures,\n    successRate,\n    recentFailures,\n    pattern,\n    severity,\n    isFlaky,\n    affectedBranches,\n    firstSeen: executions[executions.length - 1]?.timestamp || new Date(),\n    lastSeen: executions[0]?.timestamp || new Date()\n  };\n}\n\n// ============================================================================\n// Utility Functions (Reused from runs-analyze processor)\n// ============================================================================\n\nfunction calculateInconsistencyPenalty(executions: TestExecution[]): number {\n  if (executions.length < 3) return 0;\n  \n  let transitions = 0;\n  let previousStatus = executions[0].status;\n  \n  for (let i = 1; i < executions.length; i++) {\n    const currentStatus = executions[i].status;\n    if ((previousStatus === 'passed' && (currentStatus === 'failed' || currentStatus === 'error')) ||\n        ((previousStatus === 'failed' || previousStatus === 'error') && currentStatus === 'passed')) {\n      transitions++;\n    }\n    previousStatus = currentStatus;\n  }\n  \n  return Math.min(transitions / (executions.length - 1), 1.0);\n}\n\nfunction calculateRecencyFactor(executions: TestExecution[]): number {\n  const recentWindow = Math.min(10, executions.length);\n  const recentExecutions = executions.slice(0, recentWindow);\n  \n  let weightedFailures = 0;\n  let totalWeight = 0;\n  \n  for (let i = 0; i < recentExecutions.length; i++) {\n    const weight = (recentWindow - i) / recentWindow;\n    totalWeight += weight;\n    \n    if (recentExecutions[i].status === 'failed' || recentExecutions[i].status === 'error') {\n      weightedFailures += weight;\n    }\n  }\n  \n  return totalWeight > 0 ? weightedFailures / totalWeight : 0;\n}\n\nfunction calculateBranchDiversityFactor(executions: TestExecution[]): number {\n  const branchFailures = new Map<string, number>();\n  const branchCounts = new Map<string, number>();\n  \n  for (const execution of executions) {\n    const branch = execution.branch;\n    branchCounts.set(branch, (branchCounts.get(branch) || 0) + 1);\n    \n    if (execution.status === 'failed' || execution.status === 'error') {\n      branchFailures.set(branch, (branchFailures.get(branch) || 0) + 1);\n    }\n  }\n  \n  const branchesWithFailures = branchFailures.size;\n  const totalBranches = branchCounts.size;\n  \n  return totalBranches > 1 ? branchesWithFailures / totalBranches : 0;\n}\n\nfunction detectFlakinessPattern(executions: TestExecution[]): 'intermittent' | 'environmental' | 'timing' | 'unknown' {\n  const failureMessages = executions\n    .filter(e => e.failureMessage || e.errorMessage)\n    .map(e => (e.failureMessage || e.errorMessage || '').toLowerCase());\n  \n  if (failureMessages.length === 0) {\n    return 'unknown';\n  }\n  \n  const timingKeywords = ['timeout', 'wait', 'async', 'race', 'timing', 'delay'];\n  if (failureMessages.some(msg => timingKeywords.some(keyword => msg.includes(keyword)))) {\n    return 'timing';\n  }\n  \n  const envKeywords = ['connection', 'network', 'unavailable', 'service', 'port', 'bind'];\n  if (failureMessages.some(msg => envKeywords.some(keyword => msg.includes(keyword)))) {\n    return 'environmental';\n  }\n  \n  return 'intermittent';\n}\n\nfunction determineSeverity(\n  flakinessScore: number,\n  recentFailures: number,\n  totalRuns: number\n): 'low' | 'medium' | 'high' | 'critical' {\n  if (flakinessScore >= 0.7 || recentFailures >= 5) {\n    return 'critical';\n  } else if (flakinessScore >= 0.5 || recentFailures >= 3) {\n    return 'high';\n  } else if (flakinessScore >= 0.3 || recentFailures >= 2) {\n    return 'medium';\n  } else {\n    return 'low';\n  }\n}\n\n// ============================================================================\n// Database Storage Functions\n// ============================================================================\n\n/**\n * Store recomputed result\n */\nasync function storeRecomputedResult(\n  prisma: PrismaClient,\n  repository: { owner: string; repo: string },\n  testData: TestRecomputeData,\n  analysisResult: any\n): Promise<void> {\n  try {\n    if (analysisResult.isFlaky) {\n      // Store or update flaky test record\n      await prisma.flakyTest.upsert({\n        where: {\n          repositoryOwner_repositoryName_className_testName: {\n            repositoryOwner: repository.owner,\n            repositoryName: repository.repo,\n            className: testData.className,\n            testName: testData.testName\n          }\n        },\n        update: {\n          flakinessScore: analysisResult.flakinessScore,\n          totalRuns: analysisResult.totalRuns,\n          failures: analysisResult.failures,\n          successRate: analysisResult.successRate,\n          recentFailures: analysisResult.recentFailures,\n          pattern: analysisResult.pattern,\n          severity: analysisResult.severity,\n          lastSeen: analysisResult.lastSeen,\n          affectedBranches: analysisResult.affectedBranches,\n          updatedAt: new Date()\n        },\n        create: {\n          repositoryOwner: repository.owner,\n          repositoryName: repository.repo,\n          className: testData.className,\n          testName: testData.testName,\n          flakinessScore: analysisResult.flakinessScore,\n          totalRuns: analysisResult.totalRuns,\n          failures: analysisResult.failures,\n          successRate: analysisResult.successRate,\n          recentFailures: analysisResult.recentFailures,\n          pattern: analysisResult.pattern,\n          severity: analysisResult.severity,\n          firstSeen: analysisResult.firstSeen,\n          lastSeen: analysisResult.lastSeen,\n          affectedBranches: analysisResult.affectedBranches,\n          createdAt: new Date(),\n          updatedAt: new Date()\n        }\n      });\n    } else {\n      // Remove from flaky tests if no longer flaky\n      await prisma.flakyTest.deleteMany({\n        where: {\n          repositoryOwner: repository.owner,\n          repositoryName: repository.repo,\n          className: testData.className,\n          testName: testData.testName\n        }\n      });\n    }\n  } catch (error) {\n    logger.error({\n      repository: `${repository.owner}/${repository.repo}`,\n      test: `${testData.className}.${testData.testName}`,\n      error: error instanceof Error ? error.message : String(error)\n    }, 'Failed to store recomputed result');\n    throw error;\n  }\n}\n\n// ============================================================================\n// Summary and Reporting Functions\n// ============================================================================\n\n/**\n * Generate comprehensive summary\n */\nasync function generateRecomputeSummary(\n  prisma: PrismaClient,\n  jobData: TestsRecomputeJobData,\n  batchResults: BatchResult[]\n): Promise<RecomputeSummary> {\n  try {\n    // Load current flaky tests for summary\n    const currentFlakyTests = await prisma.flakyTest.findMany({\n      where: {\n        repositoryOwner: jobData.repository.owner,\n        repositoryName: jobData.repository.repo\n      },\n      orderBy: { flakinessScore: 'desc' }\n    });\n    \n    // Calculate aggregates\n    const totalTestsAnalyzed = batchResults.reduce((sum, batch) => sum + batch.testsProcessed, 0);\n    const newFlakyCount = currentFlakyTests.length;\n    const averageFlakinessScore = newFlakyCount > 0 \n      ? currentFlakyTests.reduce((sum, test) => sum + test.flakinessScore, 0) / newFlakyCount \n      : 0;\n    \n    // Pattern analysis\n    const patternsDetected: Record<string, number> = {};\n    const severityDistribution: Record<string, number> = {};\n    \n    for (const test of currentFlakyTests) {\n      patternsDetected[test.pattern] = (patternsDetected[test.pattern] || 0) + 1;\n      severityDistribution[test.severity] = (severityDistribution[test.severity] || 0) + 1;\n    }\n    \n    // Find extremes\n    const mostFlakyTest = currentFlakyTests[0] ? {\n      className: currentFlakyTests[0].className,\n      testName: currentFlakyTests[0].testName,\n      score: currentFlakyTests[0].flakinessScore\n    } : undefined;\n    \n    const leastFlakyTest = currentFlakyTests[currentFlakyTests.length - 1] ? {\n      className: currentFlakyTests[currentFlakyTests.length - 1].className,\n      testName: currentFlakyTests[currentFlakyTests.length - 1].testName,\n      score: currentFlakyTests[currentFlakyTests.length - 1].flakinessScore\n    } : undefined;\n    \n    return {\n      totalTestsAnalyzed,\n      previousFlakyCount: 0, // Would need to be tracked separately\n      newFlakyCount,\n      averageFlakinessScore,\n      mostFlakyTest,\n      leastFlakyTest,\n      patternsDetected,\n      severityDistribution\n    };\n    \n  } catch (error) {\n    logger.error({\n      repository: `${jobData.repository.owner}/${jobData.repository.repo}`,\n      error: error instanceof Error ? error.message : String(error)\n    }, 'Failed to generate recompute summary');\n    \n    // Return basic summary on error\n    return {\n      totalTestsAnalyzed: batchResults.reduce((sum, batch) => sum + batch.testsProcessed, 0),\n      previousFlakyCount: 0,\n      newFlakyCount: 0,\n      averageFlakinessScore: 0,\n      patternsDetected: {},\n      severityDistribution: {}\n    };\n  }\n}\n\n/**\n * Update quarantine status for tests\n */\nasync function updateQuarantineStatus(\n  prisma: PrismaClient,\n  repository: { owner: string; repo: string }\n): Promise<{ quarantined: number; unquarantined: number }> {\n  try {\n    // Quarantine critical and high severity tests\n    const toQuarantine = await prisma.flakyTest.updateMany({\n      where: {\n        repositoryOwner: repository.owner,\n        repositoryName: repository.repo,\n        severity: { in: ['critical', 'high'] },\n        quarantined: false\n      },\n      data: {\n        quarantined: true,\n        quarantinedAt: new Date()\n      }\n    });\n    \n    // Unquarantine low severity tests\n    const toUnquarantine = await prisma.flakyTest.updateMany({\n      where: {\n        repositoryOwner: repository.owner,\n        repositoryName: repository.repo,\n        severity: { in: ['low'] },\n        quarantined: true\n      },\n      data: {\n        quarantined: false,\n        quarantinedAt: null\n      }\n    });\n    \n    return {\n      quarantined: toQuarantine.count,\n      unquarantined: toUnquarantine.count\n    };\n    \n  } catch (error) {\n    logger.error({\n      repository: `${repository.owner}/${repository.repo}`,\n      error: error instanceof Error ? error.message : String(error)\n    }, 'Failed to update quarantine status');\n    \n    return { quarantined: 0, unquarantined: 0 };\n  }\n}\n\n// ============================================================================\n// Utility Functions\n// ============================================================================\n\n/**\n * Create empty recompute result\n */\nfunction createEmptyRecomputeResult(startTime: number): RecomputeResult {\n  return {\n    success: true,\n    recomputedTests: 0,\n    updatedFlakyTests: 0,\n    quarantinedTests: 0,\n    unquarantinedTests: 0,\n    totalExecutionsAnalyzed: 0,\n    processingTimeMs: Date.now() - startTime,\n    batchResults: [],\n    errors: [],\n    warnings: [],\n    summary: {\n      totalTestsAnalyzed: 0,\n      previousFlakyCount: 0,\n      newFlakyCount: 0,\n      averageFlakinessScore: 0,\n      patternsDetected: {},\n      severityDistribution: {}\n    }\n  };\n}\n\n// ============================================================================\n// Export Processor Factory\n// ============================================================================\n\n/**\n * Factory function for tests recompute processor\n */\nexport function testsRecomputeProcessor(prisma: PrismaClient) {\n  const processor = createTestsRecomputeProcessor(prisma);\n  \n  return async (job: Job<TestsRecomputeJobData>): Promise<RecomputeResult> => {\n    return processor(job);\n  };\n}\n\nexport default testsRecomputeProcessor;"